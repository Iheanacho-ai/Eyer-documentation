# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply surround
# them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
# for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "1s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 10000

  ## Maximum number of unwritten metrics per output.  Increasing this value
  ## allows for longer periods of output downtime without dropping metrics at the
  ## cost of higher maximum memory usage.
  metric_buffer_limit = 100000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "5s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Log at debug level.
  # debug = false
  ## Log only error level messages.
  # quiet = false

  ## Log target controls the destination for logs and can be one of "file",
  ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
  ## is determined by the "logfile" setting.
  # logtarget = "file"

  ## Name of the file to be logged to when using the "file" logtarget.  If set to
  ## the empty string then logs are written to stderr.
  # logfile = ""

  ## The logfile will be rotated after the time interval specified.  When set
  ## to 0 no time based rotation is performed.  Logs are rotated only when
  ## written to, if there is no log activity rotation may be delayed.
   logfile_rotation_interval = "1d"

  ## The logfile will be rotated when it becomes larger than the specified
  ## size.  When set to 0 no size based rotation is performed.
   logfile_rotation_max_size = "1MB"

  ## Maximum number of rotated archives to keep, any older logs are deleted.
  ## If set to -1, no archives are removed.
  # logfile_rotation_max_archives = 5

  ## Pick a timezone to use when logging or type 'local' for local time.
  ## Example: America/Chicago
  # log_with_timezone = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# # Configuration for sending metrics to InfluxDB
# [[outputs.influxdb_v2]]
#   ## The URLs of the InfluxDB cluster nodes.
#   ##
#   ## Multiple URLs can be specified for a single cluster, only ONE of the
#   ## urls will be written to each interval.
#   ##   ex: urls = ["https://us-west-2-1.aws.cloud2.influxdata.com"]
#   urls = ["http://127.0.0.1:8086"]
#
#   ## Token for authentication.
#   token = ""
#
#   ## Organization is the name of the organization you wish to write to; must exist.
#   organization = ""
#
#   ## Destination bucket to write into.
#   bucket = ""
#
#   ## The value of this tag will be used to determine the bucket.  If this
#   ## tag is not set the 'bucket' option is used as the default.
#   # bucket_tag = ""
#
#   ## If true, the bucket tag will not be added to the metric.
#   # exclude_bucket_tag = false
#
#   ## Timeout for HTTP messages.
#   # timeout = "5s"
#
#   ## Additional HTTP headers
#   # http_headers = {"X-Special-Header" = "Special-Value"}
#
#   ## HTTP Proxy override, if unset values the standard proxy environment
#   ## variables are consulted to determine which proxy, if any, should be used.
#   # http_proxy = "http://corporate.proxy:3128"
#
#   ## HTTP User-Agent
#   # user_agent = "telegraf"
#
#   ## Content-Encoding for write request body, can be set to "gzip" to
#   ## compress body or "identity" to apply no encoding.
#   # content_encoding = "gzip"
#
#   ## Enable or disable uint support for writing uints influxdb 2.0.
#   # influx_uint_support = false
#
#   ## Optional TLS Config for use on HTTP connections.
#   # tls_ca = "/etc/telegraf/ca.pem"
#   # tls_cert = "/etc/telegraf/cert.pem"
#   # tls_key = "/etc/telegraf/key.pem"
#   ## Use TLS but skip chain & host verification
#   # insecure_skip_verify = false


# # Send telegraf metrics to file(s)
# [[outputs.file]]
#   ## Files to write to, "stdout" is a specially handled file.
#   files = ["stdout", "metrics.out"]
#
#   ## Use batch serialization format instead of line based delimiting.  The
#   ## batch format allows for the production of non line based output formats and
#   ## may more efficiently encode and write metrics.
#    use_batch_format = true
#
#   ## The file will be rotated after the time interval specified.  When set
#   ## to 0 no time based rotation is performed.
#   # rotation_interval = "0h"
#
#   ## The logfile will be rotated when it becomes larger than the specified
#   ## size.  When set to 0 no size based rotation is performed.
#   # rotation_max_size = "0MB"
#
#   ## Maximum number of rotated archives to keep, any older logs are deleted.
#   ## If set to -1, no archives are removed.
#   # rotation_max_archives = 5
#
#   ## Data format to output.
#   ## Each data format has its own unique set of configuration options, read
#   ## more about them here:
#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
#   data_format = "json"
#
#   ## Compress output data with the specifed algorithm.
#   ## If empty, compression will be disabled and files will be plain text.
#   ## Supported algorithms are "zstd", "gzip" and "zlib".
#   # compression_algorithm = ""
#
#   ## Compression level for the algorithm above.
#   ## Please note that different algorithms support different levels:
#   ##   zstd  -- supports levels 1, 3, 7 and 11.
#   ##   gzip -- supports levels 0, 1 and 9.
#   ##   zlib -- supports levels 0, 1, and 9.
#   ## By default the default compression level for each algorithm is used.
#   # compression_level = -1


# # A plugin that can transmit metrics over HTTP
 [[outputs.http]]
#   ## URL is the address to send metrics to
   url = "https://data.eyer.ai/api/telegraf"
#
#   ## Timeout for HTTP message
    timeout = "5s"
#
#   ## HTTP method, one of: "POST" or "PUT"
    method = "POST"
#
#   ## HTTP Basic Auth credentials
#   # username = "username"
#   # password = "pa$$word"
#
#   ## OAuth2 Client Credentials Grant
#   # client_id = "clientid"
#   # client_secret = "secret"
#   # token_url = "https://indentityprovider/oauth2/v1/token"
#   # audience = ""
#   # scopes = ["urn:opc:idm:__myscopes__"]
#
#   ## Goole API Auth
#   # google_application_credentials = "/etc/telegraf/example_secret.json"
#
#   ## Optional TLS Config
#   # tls_ca = "/etc/telegraf/ca.pem"
#   # tls_cert = "/etc/telegraf/cert.pem"
#   # tls_key = "/etc/telegraf/key.pem"
#   ## Use TLS but skip chain & host verification
#   # insecure_skip_verify = false
#
#   ## Optional Cookie authentication
#   # cookie_auth_url = "https://localhost/authMe"
#   # cookie_auth_method = "POST"
#   # cookie_auth_username = "username"
#   # cookie_auth_password = "pa$$word"
#   # cookie_auth_headers = '{"Content-Type": "application/json", "X-MY-HEADER":"hello"}'
#   # cookie_auth_body = '{"username": "user", "password": "pa$$word", "authenticate": "me"}'
#   ## cookie_auth_renewal not set or set to "0" will auth once and never renew the cookie
#   # cookie_auth_renewal = "5m"
#
#   ## Data format to output.
#   ## Each data format has it's own unique set of configuration options, read
#   ## more about them here:
#   ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
    data_format = "json"
#
#   ## Use batch serialization format (default) instead of line based format.
#   ## Batch format is more efficient and should be used unless line based
#   ## format is really needed.
#    use_batch_format = true
#
#   ## HTTP Content-Encoding for write request body, can be set to "gzip" to
#   ## compress body or "identity" to apply no encoding.
#   # content_encoding = "identity"
#
#   ## Additional HTTP headers
    [outputs.http.headers]
#   #   # Should be set manually to "application/json" for json data_format
#   #   Content-Type = "text/plain; charset=utf-8"
		authenticate = "your_api_key"
#
#   ## MaxIdleConns controls the maximum number of idle (keep-alive)
#   ## connections across all hosts. Zero means no limit.
#   # max_idle_conn = 0
#
#   ## MaxIdleConnsPerHost, if non-zero, controls the maximum idle
#   ## (keep-alive) connections to keep per-host. If zero,
#   ## DefaultMaxIdleConnsPerHost is used(2).
#   # max_idle_conn_per_host = 2
#
#   ## Idle (keep-alive) connection timeout.
#   ## Maximum amount of time before idle connection is closed.
#   ## Zero means no limit.
#   # idle_conn_timeout = 0
#
#   ## Amazon Region
#   #region = "us-east-1"
#
#   ## Amazon Credentials
#   ## Amazon Credentials are not built unless the following aws_service
#   ## setting is set to a non-empty string. It may need to match the name of
#   ## the service output to as well
#   #aws_service = "execute-api"
#
#   ## Credentials are loaded in the following order
#   ## 1) Web identity provider credentials via STS if role_arn and web_identity_token_file are specified
#   ## 2) Assumed credentials via STS if role_arn is specified
#   ## 3) explicit credentials from 'access_key' and 'secret_key'
#   ## 4) shared profile from 'profile'
#   ## 5) environment variables
#   ## 6) shared credentials file
#   ## 7) EC2 Instance Profile
#   #access_key = ""
#   #secret_key = ""
#   #token = ""
#   #role_arn = ""
#   #web_identity_token_file = ""
#   #role_session_name = ""
#   #profile = ""
#   #shared_credential_file = ""
#
#   ## Optional list of statuscodes (<200 or >300) upon which requests should not be retried
#   # non_retryable_statuscodes = [409, 413]



###############################################################################
#                            PROCESSOR PLUGINS                                #
###############################################################################


# # Transforms tag and field values with regex pattern
 [[processors.regex]]
#   ## Tag and field conversions defined in a separate sub-tables
#   # [[processors.regex.tags]]
#   #   ## Tag to change
#   #   key = "resp_code"
#   #   ## Regular expression to match on a tag value
#   #   pattern = "^(\\d)\\d\\d$"
#   #   ## Matches of the pattern will be replaced with this string.  Use ${1}
#   #   ## notation to use the text of the first submatch.
#   #   replacement = "${1}xx"
#
    [[processors.regex.fields]]
#   #   ## Field to change
      key = "ContainerIdentifier"
#   #   ## All the power of the Go regular expressions available here
#   #   ## For example, named subgroups
	  pattern = "[a-f-]+"
      replacement = "${1}"
#   #   ## If result_key is present, a new field will be created
#   #   ## instead of changing existing field
#   #   result_key = "AtomID"
#
#   ## Multiple conversions may be applied for one field sequentially
#   ## Let's extract one more value
#   # [[processors.regex.fields]]
#   #   key = "request"
#   #   pattern = ".*category=(\\w+).*"
#   #   replacement = "${1}"
#   #   result_key = "search_category"



# # Convert values to another metric value type
 [[processors.converter]]
#   ## Tags to convert
#   ##
#   ## The table key determines the target type, and the array of key-values
#   ## select the keys to convert.  The array may contain globs.
#   ##   <target-type> = [<tag-key>...]
#   [processors.converter.tags]
#     measurement = []
#     string = []
#     integer = []
#     unsigned = []
#     boolean = []
#     float = []
#
#   ## Fields to convert
#   ##
#   ## The table key determines the target type, and the array of key-values
#   ## select the keys to convert.  The array may contain globs.
#   ##   <target-type> = [<field-key>...]
   [processors.converter.fields]
#     measurement = []
#     tag = []
#     string = []
     integer = ["AtomInBadState","DeadlockDetected","LowMemory","OutOfMemory","Restarting","TooManyOpenFiles"]
#     unsigned = []
#     boolean = []
     float = ["ContainerIdentifier"]



# # Map enum values according to given table.
 [[processors.enum]]
   [[processors.enum.mapping]]
#     ## Name of the field to map. Globs accepted.
     field = "Status"
#
#     ## Name of the tag to map. Globs accepted.
#     # tag = "status"
#
#     ## Destination tag or field to be used for the mapped value.  By default the
#     ## source tag or field is used, overwriting the original value.
#     dest = "StatusCode"
#
#     ## Default value to be used for all values not contained in the mapping
#     ## table.  When unset, the unmodified value for the field will be used if no
#     ## match is found.
#     # default = 0
#
#     ## Table of mappings
     [processors.enum.mapping.value_mappings]
      
	 RUNNING = 0
	 INITIALIZING = 1
	 INIT_UPDATING = 1
	 PAUSING = 1
	 PAUSED = 1
	 PAUSING_FOR_STOP = 1
	 PAUSED_FOR_STOP = 1
	 STOPPING = 1
	 STOPPED = 1


###############################################################################
#                            AGGREGATOR PLUGINS                               #
###############################################################################


# # Keep the aggregate basicstats of each metric passing through.
 [[aggregators.basicstats]]
#   ## The period on which to flush & clear the aggregator.
   period = "60s"
#
#   ## If true, the original metric will be dropped by the
#   ## aggregator and will not get sent to the output plugins.
   drop_original = true
#
#   ## Configures which basic stats to push as fields
#    stats = ["count", "min", "max", "mean", "stdev", "s2", "sum"]
    stats = ["max", "mean", "sum"]





###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################



# # Read JMX metrics from a Jolokia REST agent endpoint
[[inputs.jolokia2_agent]]
urls = ["http://jolokia_ip:8778/jolokia"]

[[inputs.jolokia2_agent.metric]]
     name  = "Java_runtime"
     mbean = "java.lang:type=OperatingSystem"
     paths = ["ProcessCpuLoad"]

[[inputs.jolokia2_agent.metric]]
     name  = "Java_runtime"
     mbean = "java.lang:type=OperatingSystem"
     paths = ["SystemCpuLoad"]
	 
[[inputs.jolokia2_agent.metric]]
     name  = "Java_runtime"
     mbean = "java.lang:type=OperatingSystem"
     paths = ["CommittedVirtualMemorySize"]
	 
[[inputs.jolokia2_agent.metric]]
     name  = "Java_runtime"
     mbean = "java.lang:type=OperatingSystem"
     paths = ["TotalPhysicalMemorySize"]

   [[inputs.jolokia2_agent.metric]]
     name  = "Java_runtime"
     mbean = "java.lang:type=Memory"
     paths = ["HeapMemoryUsage"]
	 
	 [[inputs.jolokia2_agent.metric]]
     name  = "ActiveMQ"
     mbean = "org.apache.activemq:type=Broker,brokerName=atomq"
     paths = ["MemoryPercentUsage"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=Config"
	 paths = ["Restarting"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=Config"
	 paths = ["Status"]

	 [[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=Config"
	 paths = ["ContainerIdentifier"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=Scheduler"
	 paths = ["ExecutingSchedulesCount"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=Scheduler"
	 paths = ["MissedSchedulesCount"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=Scheduler"
	 paths = ["ScheduleCount"]	 
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ProcessSummaryReportingService"
	 paths = ["PendingExecutionCount"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ProcessSummaryReportingService"
	 paths = ["PendingReportCount"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ProcessSummaryReportingService"
	 paths = ["PendingResultCount"]	 

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ResourceManager"
	 paths = ["LowMemory"]	 
	 
	 [[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ResourceManager"
	 paths = ["OutOfMemory"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ResourceManager"
	 paths = ["TooManyOpenFiles"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ResourceManager"
	 paths = ["DeadlockDetected"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ResourceManager"
	 paths = ["AtomInBadState"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["AverageExecutionQueueTime"]	 
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["AverageExecutionTime"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["LocalExecutionCounts"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["LocalRunningWorkersCount"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["MaxQueuedExecutions"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["QueuedExecutionEstimatedCount"]

	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["QueuedExecutionTimeout"]	 
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=ExecutionManager"
	 paths = ["RunningExecutionEstimatedCount"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "Atom"
	 mbean = "com.boomi.container.services:type=MessageQueueFactory"
	 paths = ["PendingMessageCount"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "AtomProcessTrackQueue"
	 mbean = "com.boomi.container.services:type=MessageQueue,queueId=process-track"
	 paths = ["PendingUploadMessageCount"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "AtomAcknowledgementTrackQueue"
	 mbean = "com.boomi.container.services:type=MessageQueue,queueId=acknowledgement-track"
	 paths = ["PendingUploadMessageCount"]
	 
	[[inputs.jolokia2_agent.metric]]	 
	 name = "AtomEventQueue"
	 mbean = "com.boomi.container.services:type=MessageQueue,queueId=event"
	 paths = ["PendingUploadMessageCount"]

 	[[inputs.jolokia2_agent.metric]]  
    	name = "Atom"
    	mbean = "com.boomi.container.services:type=MessagePollerThread"
    	paths = ["DownloadStats/connectFailureCount"]
		
 	[[inputs.jolokia2_agent.metric]]  
    	name = "Atom"
    	mbean = "com.boomi.container.services:type=MessagePollerThread"
    	paths = ["DownloadStats/deliveredMessageCount"]
	